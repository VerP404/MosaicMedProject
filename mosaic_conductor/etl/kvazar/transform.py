import json
from datetime import date
from collections import Counter
from dagster import asset, Field, String, OpExecutionContext, AssetIn
from config.settings import ORGANIZATIONS
from mosaic_conductor.etl.common.connect_db import connect_to_db

# –°–ª–æ–≤–∞—Ä—å (–Ω–∞–±–æ—Ä) —Ç–∞–±–ª–∏—Ü, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–∞.
SKIP_CHECK_TABLES = {"load_data_journal_appeals"}  # –¥–æ–±–∞–≤—å—Ç–µ —Å—é–¥–∞ –∏–º–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –Ω—É–∂–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É


def make_columns_unique(columns):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ (–¥–æ–±–∞–≤–ª—è–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å—ã –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è—Ö)."""
    counts = {}
    new_cols = []
    for col in columns:
        if col in counts:
            counts[col] += 1
            new_cols.append(f"{col}_{counts[col]}")
        else:
            counts[col] = 0
            new_cols.append(col)
    return new_cols


def normalize(col: str) -> str:
    """
    –£–¥–∞–ª—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–π —Å—É—Ñ—Ñ–∏–∫—Å –≤–∏–¥–∞ _<—á–∏—Å–ª–æ> –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–∞.
    –ù–∞–ø—Ä–∏–º–µ—Ä, '–§–∞–º–∏–ª–∏—è_1' -> '–§–∞–º–∏–ª–∏—è'
    """
    parts = col.split("_")
    if len(parts) > 1 and parts[-1].isdigit():
        return "_".join(parts[:-1])
    return col


@asset(
    config_schema={
        "mapping_file": Field(String),
        "table_name": Field(String),
        "is_talon": Field(bool, default_value=False)
    },
    ins={"kvazar_extract": AssetIn()}
)
def kvazar_transform(context: OpExecutionContext, kvazar_extract: dict) -> dict:
    """
    –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö:
      1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –∏–∑ mapping.json.
      2. –î–µ–ª–∞–µ—Ç –∏–º–µ–Ω–∞ —Å—Ç–æ–ª–±—Ü–æ–≤ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏.
      3. –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –≤ SKIP_CHECK_TABLES, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ —Å —É—á—ë—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.
      4. –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç —Å—Ç–æ–ª–±—Ü—ã —Å–æ–≥–ª–∞—Å–Ω–æ mapping_fields.
      5. –û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –æ–∂–∏–¥–∞–µ–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã.
      6. –ï—Å–ª–∏ –∑–∞–¥–∞–Ω–æ "check_fields" –≤ –º–∞–ø–ø–∏–Ω–≥–µ, —É–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.
      7. –ó–∞–ø–æ–ª–Ω—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º "-".
      8. –ü—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–∞–ª–æ–Ω–æ–≤ –≤—ã—á–∏—Å–ª—è–µ—Ç is_complex, report_year –∏ report_month.
      9. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª–∏–±–æ –µ–¥–∏–Ω—ã–π DataFrame, –ª–∏–±–æ —Å–ª–æ–≤–∞—Ä—å —Å –≤–µ—Ç–∫–∞–º–∏ "normal" –∏ "complex".
    """
    config = context.op_config
    mapping_file = config["mapping_file"]
    table_name = config["table_name"]

    df = kvazar_extract.get("data")
    if df is None:
        context.log.info("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏!")
        raise ValueError("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏.")
    # –î–µ–ª–∞–µ–º –∏–º–µ–Ω–∞ —Å—Ç–æ–ª–±—Ü–æ–≤ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏
    df.columns = make_columns_unique(df.columns)
    actual_cols = list(df.columns)
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞–ø–ø–∏–Ω–≥
    with open(mapping_file, "r", encoding="utf-8") as f:
        mappings = json.load(f)
    table_config = mappings.get("tables", {}).get(table_name, {})
    column_mapping = table_config.get("mapping_fields", {})

    # –°–ø–∏—Å–æ–∫ –æ–∂–∏–¥–∞–µ–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –º–∞–ø–ø–∏–Ω–≥—É (–∫–ª—é—á–∏)
    expected_original_cols = list(column_mapping.keys())

    # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ –≤ SKIP_CHECK_TABLES, –≤—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤.
    if table_name not in SKIP_CHECK_TABLES:
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –æ–∂–∏–¥–∞–µ–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –∏–º–µ–Ω–∏
        expected_counts = Counter(normalize(col) for col in expected_original_cols)
        actual_counts = Counter(normalize(col) for col in actual_cols)

        missing_in_csv = {key: expected_counts[key] - actual_counts.get(key, 0)
                          for key in expected_counts if actual_counts.get(key, 0) < expected_counts[key]}
        if missing_in_csv:
            context.log.info(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã –≤ CSV (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ): {missing_in_csv}")
            raise KeyError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –≤ CSV: {missing_in_csv}")

        extra_in_csv = {normalize(col) for col in actual_cols} - {normalize(col) for col in expected_original_cols}
        if extra_in_csv:
            context.log.info(f"‚ö†Ô∏è –õ–∏—à–Ω–∏–µ —Å—Ç–æ–ª–±—Ü—ã (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ) –≤ CSV: {extra_in_csv}. –û–Ω–∏ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã.")
    else:
        context.log.info(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {table_name}.")

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å–æ–≥–ª–∞—Å–Ω–æ mapping_fields
    df = df.rename(columns=column_mapping)
    expected_cols = list(column_mapping.values())
    actual_transformed_cols = list(df.columns)
    missing_after_rename = set(expected_cols) - set(actual_transformed_cols)
    if missing_after_rename:
        context.log.info(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: {missing_after_rename}")
        raise KeyError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: {missing_after_rename}")
    extra_after_rename = set(actual_transformed_cols) - set(expected_cols)
    if extra_after_rename:
        context.log.info(f"‚ö†Ô∏è –õ–∏—à–Ω–∏–µ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: {extra_after_rename}. –û–Ω–∏ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã.")
    df = df[expected_cols]
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: –µ—Å–ª–∏ –≤ mapping –∑–∞–¥–∞–Ω–æ –ø–æ–ª–µ "check_fields", —É–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    check_fields = table_config.get("check_fields", [])
    if check_fields:
        original_len = len(df)
        df = df.dropna(subset=check_fields)
        context.log.info(
            f"‚ö†Ô∏è –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ —Å—Ç—Ä–æ–∫: {original_len - len(df)} (—É–¥–∞–ª–µ–Ω—ã —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö: {check_fields})"
        )
    else:
        context.log.info("–ü–æ–ª–µ 'check_fields' –Ω–µ –∑–∞–¥–∞–Ω–æ ‚Äì –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –ø—É—Å—Ç—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º.")

    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –∏–∑ –ë–î –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º "-"
    engine, conn = connect_to_db(organization=ORGANIZATIONS, context=context)
    sql = f"""
          SELECT column_name 
          FROM information_schema.columns 
          WHERE table_name = '{table_name}' 
            AND data_type = 'character varying';
        """
    with conn.cursor() as cursor:
        cursor.execute(sql)
        db_columns = [row[0] for row in cursor.fetchall()]
    conn.close()
    if not db_columns:
        context.log.info(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {table_name}.")
        raise ValueError(f"‚ùå –ù–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {table_name}.")
    for col in db_columns:
        if col not in df.columns:
            context.log.info(f"‚ö†Ô∏è –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π —Å—Ç–æ–ª–±–µ—Ü '{col}' —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º '-' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            df[col] = "-"

    # –û—á–∏—Å—Ç–∫–∞ DataFrame –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
    df = df.replace('`', '', regex=True)
    # –ï—Å–ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —Ç–∞–ª–æ–Ω—ã, –≤—ã—á–∏—Å–ª—è–µ–º is_complex, report_year –∏ report_month
    if config.get("is_talon", False) or table_name in ["load_data_talons", "load_data_complex_talons"]:
        context.log.info("‚ÑπÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–∞–ª–æ–Ω–æ–≤ ‚Äì –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ª–±—Ü–∞ is_complex –∫–∞–∫ boolean.")
        df["is_complex"] = False
        df.drop(columns=['report_year', 'report_month'], errors='ignore', inplace=True)

        def compute_report_year(report_period, treatment_end):
            return treatment_end[-4:] if report_period == '-' else report_period[-4:]

        def compute_report_month(report_period, treatment_end):
            current_date = date.today()
            if report_period == '-':
                if current_date.day <= 4:
                    month_from_treatment = int(treatment_end[3:5]) if len(treatment_end) >= 6 else current_date.month
                    return current_date.month if month_from_treatment == current_date.month else (
                        12 if current_date.month == 1 else current_date.month - 1)
                else:
                    return current_date.month
            else:
                month_mapping = {
                    '–Ø–Ω–≤–∞—Ä—è': 1, '–§–µ–≤—Ä–∞–ª—è': 2, '–ú–∞—Ä—Ç–∞': 3, '–ê–ø—Ä–µ–ª—è': 4,
                    '–ú–∞—è': 5, '–ò—é–Ω—è': 6, '–ò—é–ª—è': 7, '–ê–≤–≥—É—Å—Ç–∞': 8,
                    '–°–µ–Ω—Ç—è–±—Ä—è': 9, '–û–∫—Ç—è–±—Ä—è': 10, '–ù–æ—è–±—Ä—è': 11, '–î–µ–∫–∞–±—Ä—è': 12
                }
                month_str = report_period.split()[0].strip()
                return month_mapping.get(month_str, None)

        years = [
            compute_report_year(rp, te)
            for rp, te in zip(df['report_period'], df['treatment_end'])
        ]
        months = [
            compute_report_month(rp, te)
            for rp, te in zip(df['report_period'], df['treatment_end'])
        ]

        df['report_year'] = years
        df['report_month'] = months

        grouped = df.groupby(["talon", "source"])
        for (talon, source), group in grouped:
            if len(group) > 1:
                df.loc[group.index, "is_complex"] = True
        df["is_complex"] = df["is_complex"].fillna(False).astype(bool)

        normal_df = df[df["is_complex"] == False].copy()
        complex_df = df[df["is_complex"] == True].copy()
        context.log.info(
            f"üîÑ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}. –ù–æ—Ä–º–∞–ª—å–Ω—ã—Ö: {len(normal_df)}, –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö: {len(complex_df)}."
        )
        return {
            "normal": {"table_name": "load_data_talons", "data": normal_df},
            "complex": {"table_name": "load_data_complex_talons", "data": complex_df}
        }
    else:
        context.log.info(f"‚úÖ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è {table_name} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}")
        return {"table_name": table_name, "data": df}
