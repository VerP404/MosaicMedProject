import hashlib
import os
import time
import json
import fnmatch

from dagster import sensor, RunRequest, SkipReason

from config.settings import ORGANIZATIONS
from mosaic_conductor.etl.kvazar import (
    kvazar_job_eln,
    kvazar_job_emd,
    kvazar_job_recipes,
    kvazar_job_death,
    kvazar_job_reference,
    kvazar_job_analysis_orders,
    iszl_job_dn,
    iszl_job_people,
    wo_old_job_talon,
    wo_old_job_doctors,
    wo_job_talon,
    wo_job_doctors,
    wo_job_detailed,
    iszl_job_dn_work,
    wo_job_errorlog,
    kvazar_job_load_journal_appeals,
)

MIN_FILE_AGE_SECONDS = 30


def _load_state(context) -> dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ cursor —Å–ª–æ–≤–∞—Ä—å –≤–∏–¥–∞ {filename: run_key}."""
    if context.cursor:
        return json.loads(context.cursor)
    return {}


def _save_state(context, state: dict):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä—å {filename: run_key} –≤ cursor —Å–µ–Ω—Å–æ—Ä–∞."""
    context.update_cursor(json.dumps(state, ensure_ascii=False))


def create_sensor(job, sensor_name, description, data_folder, table_name, mapping_file):
    @sensor(job=job, name=sensor_name, description=description)
    def _sensor(context):
        sensor_state = _load_state(context)  # {filename: run_key}

        if not os.path.exists(mapping_file):
            context.log.info(f"‚ùå –§–∞–π–ª –º–∞–ø–ø–∏–Ω–≥–∞ {mapping_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            yield SkipReason("Mapping file not found.")
            return

        with open(mapping_file, "r", encoding="utf-8") as f:
            mapping = json.load(f)
        table_config = mapping.get("tables", {}).get(table_name)
        if not table_config:
            context.log.info(f"‚ùå –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã '{table_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {mapping_file}.")
            yield SkipReason("Mapping config for table not found.")
            return

        if not os.path.exists(data_folder):
            context.log.info(f"‚ùå –ü–∞–ø–∫–∞ {data_folder} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            yield SkipReason("Data folder not found.")
            return

        files = os.listdir(data_folder)
        if not files:
            context.log.info(f"üìÇ –ü–∞–ø–∫–∞ {data_folder} –ø—É—Å—Ç–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–∏–∫.")
            yield SkipReason("–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ.")
            return

        now = time.time()
        valid_files = []
        invalid_files = []

        file_pattern = table_config.get("file", {}).get("file_pattern", "")
        file_format = table_config.get("file", {}).get("file_format", "")
        valid_pattern = f"{file_pattern}.{file_format}"

        for file in files:
            file_path = os.path.join(data_folder, file)
            if fnmatch.fnmatch(file, valid_pattern):
                mod_time = os.path.getmtime(file_path)
                age = now - mod_time
                if age >= MIN_FILE_AGE_SECONDS:
                    valid_files.append(file)
                else:
                    context.log.info(f"–§–∞–π–ª {file} –µ—â—ë –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≥—Ä—É–∂–µ–Ω (–≤–æ–∑—Ä–∞—Å—Ç {age:.0f} —Å–µ–∫.).")
            else:
                invalid_files.append(file)

        for file in invalid_files:
            file_path = os.path.join(data_folder, file)
            try:
                os.remove(file_path)
                context.log.info(f"–£–¥–∞–ª—ë–Ω –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
            except Exception as e:
                context.log.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {file_path}: {e}")

        if not valid_files:
            context.log.info("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.")
            yield SkipReason("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.")
            return

        for file in valid_files:
            file_path = os.path.join(data_folder, file)
            current_size = os.path.getsize(file_path)
            existing_size = sensor_state.get(file)

            if existing_size == current_size:
                # –§–∞–π–ª —É–∂–µ –≤—Å—Ç—Ä–µ—á–∞–ª—Å—è
                runs = context.instance.get_runs()
                matching_run = next(
                    (r for r in runs if r.tags.get("dagster/run_key") == f"{file}-{existing_size}"),
                    None
                )
                if matching_run:
                    if not matching_run.is_finished:
                        context.log.info(f"–§–∞–π–ª {file} (—Ä–∞–∑–º–µ—Ä {current_size}) —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                        continue
                    elif matching_run.is_success:
                        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª, —á–∏—Å—Ç–∏–º state
                        try:
                            os.remove(file_path)
                            context.log.info(f"–§–∞–π–ª {file} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ —É–¥–∞–ª—ë–Ω.")
                        except Exception as e:
                            context.log.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file}: {e}")
                        del sensor_state[file]
                        continue
                    elif matching_run.is_failure:
                        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É –æ—à–∏–±–æ–∫
                        error_folder = os.path.join(data_folder, "errors")
                        os.makedirs(error_folder, exist_ok=True)
                        new_file_name = f"{file}_{int(time.time())}_error"
                        new_file_path = os.path.join(error_folder, new_file_name)
                        try:
                            os.rename(file_path, new_file_path)
                            context.log.warning(f"–§–∞–π–ª {file} –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –æ—à–∏–±–∫–æ–π. –ü–µ—Ä–µ–º–µ—â—ë–Ω –≤ {new_file_path}.")
                        except Exception as e:
                            context.log.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file} –≤ –ø–∞–ø–∫—É –æ—à–∏–±–æ–∫: {e}")
                        del sensor_state[file]
                        continue
                else:
                    # ‚ö†Ô∏è –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä —Å–æ–≤–ø–∞–¥–∞–µ—Ç, –Ω–æ –∑–∞–ø—É—Å–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —É–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å—å
                    context.log.warning(
                        f"–§–∞–π–ª {file} (—Ä–∞–∑–º–µ—Ä {current_size}) —É–∂–µ –≤ state, "
                        "–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∑–∞–ø—É—Å–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–¥–∞–ª—è–µ–º –∏–∑ state."
                    )
                    del sensor_state[file]
                    # –õ–∏–±–æ –º–æ–∂–µ–º —Å—Ä–∞–∑—É –∑–∞–ø—É—Å—Ç–∏—Ç—å –Ω–æ–≤—ã–π RunRequest, –µ—Å–ª–∏ –Ω–∞–¥–æ
                    # continue
            else:
                # –§–∞–π–ª –Ω–æ–≤—ã–π –∏–ª–∏ –∏–∑–º–µ–Ω—ë–Ω (—Ä–∞–∑–º–µ—Ä –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è)
                new_run_key = f"{file}-{current_size}"
                context.log.info(f"–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –¥–ª—è —Ñ–∞–π–ª–∞ {file} (—Ä–∞–∑–º–µ—Ä {current_size}), run_key={new_run_key}")

                run_config = {
                    # –≤–∞—à –∫–æ–Ω—Ñ–∏–≥
                }

                yield RunRequest(run_key=new_run_key, run_config=run_config)
                sensor_state[file] = current_size

        _save_state(context, sensor_state)

    return _sensor


# ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–Ω—Å–æ—Ä–æ–≤
kvazar_sensor_eln = create_sensor(
    kvazar_job_eln,
    "kvazar_sensor_eln",
    "–ö–≤–∞–∑–∞—Ä: –õ–∏—Å—Ç–∫–∏ –Ω–µ—Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏",
    "mosaic_conductor/etl/data/kvazar/eln",
    "load_data_sick_leave_sheets",
    "mosaic_conductor/etl/config/mapping.json"
)

kvazar_sensor_emd = create_sensor(
    kvazar_job_emd,
    "kvazar_sensor_emd",
    "–ö–≤–∞–∑–∞—Ä: –ñ—É—Ä–Ω–∞–ª –≠–ú–î",
    "mosaic_conductor/etl/data/kvazar/emd",
    "load_data_emd",
    "mosaic_conductor/etl/config/mapping.json"
)

kvazar_sensor_recipes = create_sensor(
    kvazar_job_recipes,
    "kvazar_sensor_recipes",
    "–ö–≤–∞–∑–∞—Ä: –í—ã–ø–∏—Å–∫–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤",
    "mosaic_conductor/etl/data/kvazar/recipe",
    "load_data_recipes",
    "mosaic_conductor/etl/config/mapping.json"
)

kvazar_sensor_death = create_sensor(
    kvazar_job_death,
    "kvazar_sensor_death",
    "–ö–≤–∞–∑–∞—Ä: –°–º–µ—Ä—Ç–Ω–æ—Å—Ç—å",
    "mosaic_conductor/etl/data/kvazar/death",
    "load_data_death",
    "mosaic_conductor/etl/config/mapping.json"
)

kvazar_sensor_reference = create_sensor(
    kvazar_job_reference,
    "kvazar_sensor_reference",
    "–ö–≤–∞–∑–∞—Ä: –°–ø—Ä–∞–≤–∫–∏",
    "mosaic_conductor/etl/data/kvazar/reference",
    "load_data_reference",
    "mosaic_conductor/etl/config/mapping.json"
)

kvazar_sensor_analysis_orders = create_sensor(
    kvazar_job_analysis_orders,
    "kvazar_sensor_analysis_orders",
    "–ö–≤–∞–∑–∞—Ä: –ñ—É—Ä–Ω–∞–ª –∑–∞–∫–∞–∑–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤",
    "mosaic_conductor/etl/data/kvazar/analysis_orders",
    "load_data_kvazar_analysis_orders",
    "mosaic_conductor/etl/config/mapping.json"
)


@sensor(job=kvazar_job_load_journal_appeals, name="kvazar_sensor_journal_appeals", description="–ö–≤–∞–∑–∞—Ä: –ñ—É—Ä–Ω–∞–ª –æ–±—Ä–∞—â–µ–Ω–∏–π (CSV —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ)")
def kvazar_sensor_journal_appeals(context):
    directory = "mosaic_conductor/etl/data/kvazar/appeals"
    if not os.path.exists(directory):
        context.log.info(f"–ü–∞–ø–∫–∞ {directory} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        yield SkipReason("–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return

    files = [os.path.join(directory, f) for f in os.listdir(directory) if f.lower().endswith(".csv")]
    if not files:
        context.log.info(f"CSV –≤ {directory} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        yield SkipReason("–ù–µ—Ç CSV –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
        return

    state = _load_state(context)
    now = time.time()
    new_state = state.copy()

    for path in files:
        file_name = os.path.basename(path)
        age = now - os.path.getmtime(path)
        size = os.path.getsize(path)

        if age < MIN_FILE_AGE_SECONDS:
            context.log.info(f"–§–∞–π–ª {file_name} —Å–ª–∏—à–∫–æ–º —Å–≤–µ–∂–∏–π ({age:.0f} —Å–µ–∫.)")
            continue

        previous = state.get(file_name)
        if previous and previous.get("size") == size:
            run_key = previous.get("run_key")
            runs = context.instance.get_runs()
            matching = next((r for r in runs if r.tags.get("dagster/run_key") == run_key), None)
            if matching:
                if matching.is_success:
                    try:
                        os.remove(path)
                        context.log.info(f"–§–∞–π–ª {file_name} —É–¥–∞–ª—ë–Ω –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏")
                    except OSError as exc:
                        context.log.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {path}: {exc}")
                    new_state.pop(file_name, None)
                elif matching.is_finished:
                    context.log.warning(f"–ó–∞–ø—É—Å–∫ —Å run_key={run_key} –∑–∞–≤–µ—Ä—à—ë–Ω –Ω–µ—É—Å–ø–µ—à–Ω–æ, —Ñ–∞–π–ª {file_name} –æ—Å—Ç–∞—ë—Ç—Å—è")
                else:
                    context.log.info(f"–§–∞–π–ª {file_name} —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è, –ø—Ä–æ–ø—É—Å–∫")
                continue
            else:
                context.log.warning(f"Run –¥–ª—è —Ñ–∞–π–ª–∞ {file_name} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ")

        run_key = f"{file_name}-{size}"
        new_state[file_name] = {"size": size, "run_key": run_key}
        yield RunRequest(
            run_key=run_key,
            run_config={
                "ops": {
                    "load_journal_appeals_op": {
                        "config": {"csv_path": path}
                    }
                }
            }
        )

    _save_state(context, new_state)

iszl_sensor_dn = create_sensor(
    iszl_job_dn,
    "iszl_sensor_dn",
    "–ò–°–ó–õ: –ù–∞—Å–µ–ª–µ–Ω–∏–µ",
    "mosaic_conductor/etl/data/iszl/dn",
    "load_data_dispansery_iszl",
    "mosaic_conductor/etl/config/mapping.json"
)

iszl_sensor_dn_work = create_sensor(
    iszl_job_dn_work,
    "iszl_sensor_dn_work",
    "–ò–°–ó–õ: –î–∏—Å–ø–∞–Ω—Å–µ—Ä–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –ø–æ –º–µ—Å—Ç—É —Ä–∞–±–æ—Ç—ã",
    "mosaic_conductor/etl/data/iszl/dn_work",
    "load_data_dn_work_iszl",
    "mosaic_conductor/etl/config/mapping.json"
)
wo_old_sensor_talon = create_sensor(
    wo_old_job_talon,
    "wo_old_sensor_talon",
    "–û–ú–°: –¢–∞–ª–æ–Ω—ã. –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è",
    "mosaic_conductor/etl/data/weboms/talon/old",
    "data_loader_omsdata",
    "mosaic_conductor/etl/config/oms_old_mapping.json"
)

wo_old_sensor_doctors = create_sensor(
    wo_old_job_doctors,
    "wo_old_sensor_doctors",
    "–û–ú–°: –í—Ä–∞—á–∏. –°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è",
    "mosaic_conductor/etl/data/weboms/doctor/old",
    "data_loader_doctordata",
    "mosaic_conductor/etl/config/oms_old_mapping.json"
)
wo_sensor_talon = create_sensor(
    wo_job_talon,
    "wo_sensor_talon",
    "–û–ú–°: –¢–∞–ª–æ–Ω—ã.",
    "mosaic_conductor/etl/data/weboms/talon/new",
    "load_data_talons",
    "mosaic_conductor/etl/config/oms_mapping.json"
)

wo_sensor_doctors = create_sensor(
    wo_job_doctors,
    "wo_sensor_doctors",
    "–û–ú–°: –í—Ä–∞—á–∏.",
    "mosaic_conductor/etl/data/weboms/doctor/new",
    "load_data_doctor",
    "mosaic_conductor/etl/config/oms_mapping.json"
)

wo_sensor_detailed = create_sensor(
    wo_job_detailed,
    "wo_sensor_detailed",
    "–û–ú–°: –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –¥–∏—Å–ø–∞–Ω—Å–µ—Ä–∏–∑–∞—Ü–∏–∏.",
    "mosaic_conductor/etl/data/weboms/detailed",
    "load_data_detailed_medical_examination",
    "mosaic_conductor/etl/config/oms_mapping.json"
)

wo_sensor_errorlog = create_sensor(
    wo_job_errorlog,
    "wo_sensor_errorlog",
    "–û–ú–°: –û—Ç–∫–∞–∑—ã –ú–≠–ö –∏ –§–õ–ö.",
    "mosaic_conductor/etl/data/weboms/errorlog",
    "load_data_error_log_talon",
    "mosaic_conductor/etl/config/oms_mapping.json"
)

iszl_sensor_people = create_sensor(
    iszl_job_people,
    "iszl_sensor_people",
    "–ò–°–ó–õ: –ù–∞—Å–µ–ª–µ–Ω–∏–µ.",
    "mosaic_conductor/etl/data/iszl/people",
    "data_loader_iszlpeople",
    "mosaic_conductor/etl/config/mapping.json"
)

kvazar_sensors = [
    kvazar_sensor_eln,
    kvazar_sensor_emd,
    kvazar_sensor_recipes,
    kvazar_sensor_death,
    kvazar_sensor_reference,
    kvazar_sensor_analysis_orders,
    iszl_sensor_dn,
    iszl_sensor_dn_work,
    iszl_sensor_people,
    wo_old_sensor_talon,
    wo_old_sensor_doctors,
    wo_sensor_talon,
    wo_sensor_doctors,
    wo_sensor_detailed,
    wo_sensor_errorlog,
    kvazar_sensor_journal_appeals
]
